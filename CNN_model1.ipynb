{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1578917579701,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MKIvjGGMAFg4",
    "outputId": "5903339b-0664-4070-a361-d43a3564b150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "###  Rer.\n",
    "#-- https://www.kaggle.com/luyujia/mnist-chainer-cnn/notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5445,
     "status": "ok",
     "timestamp": 1578917585910,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "LQXnyzGwAlVt",
    "outputId": "9a4c4377-efd0-438c-cb18-58a294669c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukiyoe-test-imgs.npz  ukiyoe-train-imgs.npz  ukiyoe-train-labels.npz\n"
     ]
    }
   ],
   "source": [
    "# 'My Drive'の表記が出ていればマウントがうまく行われています。\n",
    "# !ls 'drive/'\n",
    "!ls 'drive/My Drive/jupyter/ProbSpace/ukiyoe/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P15LTIMYm3-m"
   },
   "outputs": [],
   "source": [
    "##-- Google Colabでインストールされているパッケージの確認\n",
    "import pip\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3TNKtcYAY8R"
   },
   "outputs": [],
   "source": [
    "##-- import library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "##-- Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "##-- Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14927,
     "status": "ok",
     "timestamp": 1578917596684,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "Rw8YQv0DQw9Y",
    "outputId": "cdb99546-5ca8-4784-c3a1-8ff226f1e31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.2.0.dev20200112)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.8)\n",
      "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.0.0.dev2020011209)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
      "Requirement already satisfied: tb-nightly<2.3.0a0,>=2.2.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.2.0a20200106)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
      "Processing /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf/gast-0.3.2-cp36-none-any.whl\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.21.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (42.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "Successfully installed gast-0.3.2\n",
      "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.33.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Processing /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp36-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (42.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "\u001b[31mERROR: tf-nightly 2.2.0.dev20200112 has requirement gast==0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast\n",
      "  Found existing installation: gast 0.3.2\n",
      "    Uninstalling gast-0.3.2:\n",
      "      Successfully uninstalled gast-0.3.2\n",
      "Successfully installed gast-0.2.2\n"
     ]
    }
   ],
   "source": [
    "##-- Updata tensorflow 1.x -->  2.x\n",
    "# !pip install tensorflow-gpu \n",
    "!pip install tf-nightly \n",
    "!pip install tensorflow==2.1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18284,
     "status": "ok",
     "timestamp": 1578917600456,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iB9Vw8gFTq6R",
    "outputId": "18829706-092b-4b03-ae64-9fdfa28538af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "float32\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.floatx())\n",
    "print(tf.test.gpu_device_name())\n",
    "# tf.keras.backend.set_floatx(\"float16\")\n",
    "# print(tf.keras.backend.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMkVWI3QW0lF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74554,
     "status": "ok",
     "timestamp": 1578917657597,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "edH8CExNAXkX",
    "outputId": "65cb85aa-bd12-4a45-9228-5a97adf7b709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  Data PATH  ---###\n",
    "datapath = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/data_kfold/\"\n",
    "\n",
    "###-- Read Data\n",
    "filename_train = \"ukiyoe-dataset_kfold1_train.npz\"\n",
    "filename_validation = \"ukiyoe-dataset_kfold1_validation.npz\"\n",
    "\n",
    "X_train = np.load(datapath+filename_train)[\"img\"]\n",
    "Y_train = np.load(datapath+filename_train)[\"lbl\"]\n",
    "X_test = np.load(datapath+filename_validation)[\"img\"]\n",
    "Y_test = np.load(datapath+filename_validation)[\"lbl\"]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74068,
     "status": "ok",
     "timestamp": 1578917657598,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "mazkt_NQ-j_3",
    "outputId": "f278483e-580e-4427-b1d3-428d0f33c77e"
   },
   "outputs": [],
   "source": [
    "print(Y_train[0])\n",
    "print(X_train[3][0].shape)\n",
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[22], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2Co2pj3nogh"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###       Cutout Random Erasing       ###\n",
    "###-----------------------------------###\n",
    "###-- Rondom Erasing --###\n",
    "def eraser(input_img):\n",
    "    ##-- Parameter\n",
    "    p=0.5\n",
    "    s_l=0.02\n",
    "    s_h=0.4\n",
    "    r_1=0.3\n",
    "    r_2=1/0.3\n",
    "    v_l=0\n",
    "#     v_h=255\n",
    "    v_h=1\n",
    "    pixel_level=False\n",
    "    ##--\n",
    "    img_h, img_w, img_c = input_img.shape\n",
    "    p_1 = np.random.rand()\n",
    "\n",
    "    if p_1 > p:\n",
    "        return input_img\n",
    "\n",
    "    while True:\n",
    "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "        r = np.random.uniform(r_1, r_2)\n",
    "        w = int(np.sqrt(s / r))\n",
    "        h = int(np.sqrt(s * r))\n",
    "        left = np.random.randint(0, img_w)\n",
    "        top = np.random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            break\n",
    "\n",
    "    if pixel_level:\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "    else:\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "    input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "    return input_img\n",
    "  \n",
    "###-------------------------------------###\n",
    "###-- Batch dealing of Random Erasing --###\n",
    "###-------------------------------------###\n",
    "def RandomErase( img_train ):\n",
    "  x = []\n",
    "  for i in range( len(img_train) ):\n",
    "    tem = eraser( img_train[i] )\n",
    "    x.append( tem )\n",
    "    \n",
    "  x = np.array(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73586,
     "status": "ok",
     "timestamp": 1578917658035,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MPOcYeaInsKM",
    "outputId": "cac81603-aba5-4618-bbc5-f7ececeb1e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###-- Cutout Random Erasing --##\n",
    "X_train = RandomErase( X_train )\n",
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74242,
     "status": "ok",
     "timestamp": 1578917659096,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "2U7kKeRW9SfS",
    "outputId": "7daf67a8-a2b1-4dea-bddf-8ef762d28bc5"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[3], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_t7gxSc3xgx5"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###         Data Augmentation         ###\n",
    "###-----------------------------------###\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy.random import randint\n",
    "\n",
    "##--(Number of data, Height, Width, Channels) \n",
    "def Data_Augmentation(image):\n",
    "  ######################################\n",
    "  ###-- Set augmentation generator --###\n",
    "  ######################################\n",
    "  ##-- Rondom flip\n",
    "  rotation = ImageDataGenerator(rotation_range=20)\n",
    "  ##-- Parallel Movement align to vertical direction.\n",
    "  shift_vertical = ImageDataGenerator(height_shift_range=0.2)\n",
    "  ##-- Parallel Movement align to horizontal direction.\n",
    "  shift_horizontal = ImageDataGenerator(width_shift_range=0.2)\n",
    "  ##-- Shear transformation; shera_range describes \"angle\".\n",
    "  shear = ImageDataGenerator(shear_range=5)\n",
    "  ##-- [-5.0, 5.0] の範囲でランダムに画素値に値を足す。\n",
    "  noise = ImageDataGenerator(channel_shift_range=5.)\n",
    "  ##-- [0.3, 1.0] の範囲でランダムに明度を変更する。\n",
    "  brightness = ImageDataGenerator(brightness_range=[0.3, 1.0])\n",
    "  ##--\n",
    "  ret = []\n",
    "  for i in range( 0, len(image) ):\n",
    "    tem_img = np.reshape(image[i], [-1, image[i].shape[0], image[i].shape[1], image[i].shape[2]])\n",
    "    ##-- Create random number between 0 - 3.\n",
    "    rand_int = randint(4)\n",
    "    if rand_int == 0:\n",
    "      img_rot = rotation.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 1:\n",
    "      img_rot = shift_vertical.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 2:\n",
    "      img_rot = shift_horizontal.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 3:\n",
    "      img_rot = shear.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = noise.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 5:\n",
    "    #   img_rot = brightness.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = tem_img\n",
    "    # #--\n",
    "    # img_rot = next(img_rot)\n",
    "    # #--\n",
    "    ret.append( img_rot[0] )\n",
    "\n",
    "  ret = np.array( ret )\n",
    "  \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115746,
     "status": "ok",
     "timestamp": 1578917701436,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "cqyFRUxr2GYg",
    "outputId": "52989c71-9159-4bbf-ca6a-6d586bec2396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5408, 224, 224, 3)\n",
      "(5408, 10)\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------###\n",
    "###         Data Augmentation and Inflation         ###\n",
    "###-------------------------------------------------###\n",
    "import gc\n",
    "\n",
    "multiple = 1\n",
    "img_ori = X_train.copy()\n",
    "lbl_ori = Y_train.copy()\n",
    "for i in range( multiple ):\n",
    "  data_tem = Data_Augmentation( img_ori )\n",
    "  X_train = np.append( X_train, data_tem, axis=0 )\n",
    "  Y_train = np.append( Y_train, lbl_ori, axis=0 )\n",
    "\n",
    "del img_ori, lbl_ori\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114357,
     "status": "ok",
     "timestamp": 1578917701437,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "QTjoNisT2AK5",
    "outputId": "19540d65-c035-436d-9f13-af8fbd768452"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[457], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116007,
     "status": "ok",
     "timestamp": 1578917704078,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "I005dRcTpLrf",
    "outputId": "08666fec-7dba-4656-e4a6-c2d82a8453b3"
   },
   "outputs": [],
   "source": [
    "###-- See several image --###\n",
    "cols, rows = 5, 4\n",
    "img_num = cols * rows\n",
    "\n",
    "for i in range(img_num):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(X_train[i], cmap=cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw4GaBn8LJhB"
   },
   "outputs": [],
   "source": [
    "###-- Shuffle dataset --###\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9NYNSLba5wm"
   },
   "source": [
    "###---  Definition of each Model  ---###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLtmtymFacU4"
   },
   "source": [
    "学習およびモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 125388,
     "status": "ok",
     "timestamp": 1578917715700,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "jf4HO34XxyMB",
    "outputId": "71961912-422e-4fee-f989-936a8fd601c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 10)           20490       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 23,539,850\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##-- Select the Model\n",
    "# model = ZeroDL(_input_shape=(224, 224, 3), num_classes=num_classes)\n",
    "# model = build_model(_input_shape=(224, 224, 3), num_classes=num_classes)  #--lr=0.0005 + Adam + epoch100-150\n",
    "\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "model = tf.keras.applications.ResNet50V2(\n",
    "# model = tf.keras.applications.ResNet101(\n",
    "# model = tf.keras.applications.ResNet152(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,  #--\"max\" is global max pooling, None is ordinary max pooling\n",
    "    classes=10\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 920530,
     "status": "ok",
     "timestamp": 1578920195071,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "x75E1XijCzGl",
    "outputId": "bf31a540-c647-4170-d1af-7635930db328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5408 samples, validate on 676 samples\n",
      "Epoch 1/25\n",
      "5408/5408 - 118s - loss: 1.9455 - accuracy: 0.3234 - val_loss: 2.3532 - val_accuracy: 0.2219\n",
      "Epoch 2/25\n",
      "5408/5408 - 98s - loss: 1.5013 - accuracy: 0.4854 - val_loss: 3.0688 - val_accuracy: 0.2249\n",
      "Epoch 3/25\n",
      "5408/5408 - 99s - loss: 1.2836 - accuracy: 0.5464 - val_loss: 2.7446 - val_accuracy: 0.2781\n",
      "Epoch 4/25\n",
      "5408/5408 - 99s - loss: 1.1424 - accuracy: 0.5930 - val_loss: 1.7369 - val_accuracy: 0.3935\n",
      "Epoch 5/25\n",
      "5408/5408 - 98s - loss: 1.0453 - accuracy: 0.6402 - val_loss: 1.3261 - val_accuracy: 0.4985\n",
      "Epoch 6/25\n",
      "5408/5408 - 99s - loss: 0.9471 - accuracy: 0.6779 - val_loss: 1.0807 - val_accuracy: 0.6154\n",
      "Epoch 7/25\n",
      "5408/5408 - 98s - loss: 0.8636 - accuracy: 0.7069 - val_loss: 1.1480 - val_accuracy: 0.6021\n",
      "Epoch 8/25\n",
      "5408/5408 - 98s - loss: 0.7694 - accuracy: 0.7435 - val_loss: 0.9610 - val_accuracy: 0.6864\n",
      "Epoch 9/25\n",
      "5408/5408 - 98s - loss: 0.7027 - accuracy: 0.7652 - val_loss: 2.5176 - val_accuracy: 0.4349\n",
      "Epoch 10/25\n",
      "5408/5408 - 98s - loss: 0.6264 - accuracy: 0.7940 - val_loss: 0.9753 - val_accuracy: 0.6834\n",
      "Epoch 11/25\n",
      "5408/5408 - 98s - loss: 0.5527 - accuracy: 0.8247 - val_loss: 0.9483 - val_accuracy: 0.6864\n",
      "Epoch 12/25\n",
      "5408/5408 - 98s - loss: 0.4789 - accuracy: 0.8458 - val_loss: 0.9517 - val_accuracy: 0.6716\n",
      "Epoch 13/25\n",
      "5408/5408 - 99s - loss: 0.4284 - accuracy: 0.8730 - val_loss: 0.9945 - val_accuracy: 0.7071\n",
      "Epoch 14/25\n",
      "5408/5408 - 98s - loss: 0.3506 - accuracy: 0.8987 - val_loss: 1.0913 - val_accuracy: 0.6849\n",
      "Epoch 15/25\n",
      "5408/5408 - 99s - loss: 0.3076 - accuracy: 0.9133 - val_loss: 1.0639 - val_accuracy: 0.6760\n",
      "Epoch 16/25\n",
      "5408/5408 - 99s - loss: 0.2526 - accuracy: 0.9314 - val_loss: 1.2109 - val_accuracy: 0.6716\n",
      "Epoch 17/25\n",
      "5408/5408 - 99s - loss: 0.2203 - accuracy: 0.9410 - val_loss: 1.3845 - val_accuracy: 0.6331\n",
      "Epoch 18/25\n",
      "5408/5408 - 99s - loss: 0.1793 - accuracy: 0.9560 - val_loss: 1.5474 - val_accuracy: 0.6154\n",
      "Epoch 19/25\n",
      "5408/5408 - 98s - loss: 0.1444 - accuracy: 0.9671 - val_loss: 1.1151 - val_accuracy: 0.7027\n",
      "Epoch 20/25\n",
      "5408/5408 - 98s - loss: 0.1334 - accuracy: 0.9691 - val_loss: 1.8815 - val_accuracy: 0.6139\n",
      "Epoch 21/25\n",
      "5408/5408 - 98s - loss: 0.1142 - accuracy: 0.9754 - val_loss: 1.5103 - val_accuracy: 0.6183\n",
      "Epoch 22/25\n",
      "5408/5408 - 98s - loss: 0.1077 - accuracy: 0.9765 - val_loss: 1.3286 - val_accuracy: 0.6879\n",
      "Epoch 23/25\n",
      "5408/5408 - 98s - loss: 0.0843 - accuracy: 0.9845 - val_loss: 1.1347 - val_accuracy: 0.7278\n",
      "Epoch 24/25\n",
      "5408/5408 - 98s - loss: 0.0598 - accuracy: 0.9902 - val_loss: 1.4595 - val_accuracy: 0.6598\n",
      "Epoch 25/25\n",
      "5408/5408 - 98s - loss: 0.0510 - accuracy: 0.9915 - val_loss: 0.9874 - val_accuracy: 0.7530\n"
     ]
    }
   ],
   "source": [
    "##-- Define the optimizer\n",
    "from tensorflow.keras import optimizers, losses\n",
    "optimizer = optimizers.SGD(lr = 0.001, #--lr=0.01\n",
    "                           momentum = 0.9, #--Default: 0.9\n",
    "                           nesterov = True #--Default: False\n",
    "                           )\n",
    "# optimizer = optimizers.RMSprop(lr=0.001, rho=0.99)\n",
    "# optimizer = optimizers.Adam(lr=0.0005)\n",
    "# optimizer = optimizers.Adam(lr=0.01,\n",
    "#                             # beta_1=0.9, beta_2=0.999, #--Defoalt values\n",
    "#                             # amsgrad=True, #--AMSGrad\n",
    "#                             )\n",
    "##-- Compile the model\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 64 #-- Default: 128, 64, 32\n",
    "##-- Early stopping as es\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
    "##-- Temporary save\n",
    "#--Ref. :  https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ja\n",
    "import os\n",
    "#-- ファイル名に(`str.format`を使って)エポック数を埋め込みます\n",
    "checkpoint_path = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/check_point/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # 重みを5エポックごとに保存します\n",
    "    save_freq=5)\n",
    "##-- Run\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (X_test,Y_test), #-- validation_split=0.2\n",
    "                    verbose=2, \n",
    "                    # callbacks = [cp_callback]\n",
    "                    # callbacks = [es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2120,
     "status": "ok",
     "timestamp": 1578838539305,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iT8BX58kDM17",
    "outputId": "d076dec3-be10-45ba-d400-8edded8e28d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njxmi8IuIiIg8ZojCLyIiIvKY8f/rtxT5/mx9ewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSvFUSaz1bmM"
   },
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3i8JbBY1ZwT"
   },
   "outputs": [],
   "source": [
    "###-- モデル全体を１つのHDF5ファイルに保存します。\n",
    "datapath_model = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/save_model/\"\n",
    "model.save(datapath_model+'model1.h5')\n",
    "\n",
    "# ###-- Load model file\n",
    "# model = tf.keras.models.load_model('model1.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf5wp7TujyCN"
   },
   "source": [
    "検証データで精度チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbvZB6wdjnJD"
   },
   "source": [
    "テストデータで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1990,
     "status": "ok",
     "timestamp": 1577941877917,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "pvU-d5tlZpFf",
    "outputId": "4f8b162e-98b5-4f20-de73-e265734df4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  提出用データの読み込み  ---###\n",
    "\n",
    "###--データの読み込み\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "X_submit = load(datapath+\"ukiyoe-test-imgs.npz\")\n",
    "\n",
    "###--型をint --> float変換する。\n",
    "X_submit = X_submit.astype(np.float32)\n",
    "###-- convert from [0:255] => [0.0:1.0]\n",
    "X_submit = np.multiply(X_submit, 1.0 / 255.0)\n",
    "\n",
    "print(X_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1577941891751,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "_SJK37dOgBfC",
    "outputId": "6058c09b-aeaf-426a-e2f2-4eade36da54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###---  Prediction  ---###\n",
    "predicts = np.argmax(model.predict(X_submit), axis=1)\n",
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1577941895012,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "rU8_tPMIfxh8",
    "outputId": "ca988305-34ee-404f-8105-09e62b96b612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  y\n",
      "0   1  4\n",
      "1   2  1\n",
      "2   3  3\n",
      "3   4  1\n",
      "4   5  1\n"
     ]
    }
   ],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "\n",
    "submit = pd.DataFrame(data={\"id\": [], \"y\": []})\n",
    "submit.id = list(range(1, predicts.shape[0]+1))\n",
    "submit.y = predicts\n",
    "submit.to_csv(\"submit.csv\", index=False)\n",
    "\n",
    "print(submit.head())\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432250,
     "status": "ok",
     "timestamp": 1560433030328,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "GEAK9h1GXt8R",
    "outputId": "478c024e-a882-4dbf-9e6b-812ebf80cf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 3 ... 9 4 2]\n"
     ]
    }
   ],
   "source": [
    "###--- テストデータでテスト ---#\n",
    "##-- N = 10000; Number of test images\n",
    "i = 0\n",
    "N = 10000\n",
    "predicts = []\n",
    "while i < N:\n",
    "    i = i + 100\n",
    "    ##--\n",
    "    tem = []\n",
    "    tem_1 = []\n",
    "    tem_2 = []\n",
    "    tem_3 = []\n",
    "    tem_4 = []\n",
    "    tem_5 = []\n",
    "    ##--\n",
    "    #tem_1 = model_1.predict(test_imgs[i-100:i])\n",
    "    tem_2 = model_2.predict(test_imgs[i-100:i])\n",
    "    tem_3 = model_3.predict(test_imgs[i-100:i])\n",
    "    tem_4 = model_4.predict(test_imgs[i-100:i])\n",
    "    tem_5 = model_5.predict(test_imgs[i-100:i])\n",
    "    #tem = tem_1 + tem_2 + tem_3 + tem_4 + tem_5\n",
    "    tem = tem_2 + tem_3 + tem_4 + tem_5\n",
    "    ##--\n",
    "    predicts = np.append( predicts, np.argmax( tem , axis=1) )\n",
    "  \n",
    "predicts = predicts.astype(np.int64)\n",
    "\n",
    "predicts.shape\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "error",
     "timestamp": 1577603913673,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "FCH4zL-9dPQo",
    "outputId": "6a1ea8bd-acd8-4080-f8b6-293de81adbda"
   },
   "outputs": [],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "###-- 変数predictsに予測結果を入れて下さい\n",
    "###-- 型はnumpy.ndarrayで\n",
    "###-- shapeは(10000,)になるはずです\n",
    "###-- predicts = \n",
    "submit = pd.DataFrame(data={\"ImageId\": [], \"Label\": []})\n",
    "\n",
    "submit.ImageId = list(range(1, predicts.shape[0]+1))\n",
    "submit.Label = predicts\n",
    "\n",
    "submit.to_csv(root.joinpath(\"submit.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lbeDsG67hlH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_model1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1511,
     "status": "ok",
     "timestamp": 1578884795484,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MKIvjGGMAFg4",
    "outputId": "56fd00f2-64f8-4826-dcd0-b9f356067207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "###  Rer.\n",
    "#-- https://www.kaggle.com/luyujia/mnist-chainer-cnn/notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5881,
     "status": "ok",
     "timestamp": 1578884803067,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "LQXnyzGwAlVt",
    "outputId": "0356aa71-1864-40c8-b41d-1f7701e87607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukiyoe-test-imgs.npz  ukiyoe-train-imgs.npz  ukiyoe-train-labels.npz\n"
     ]
    }
   ],
   "source": [
    "# 'My Drive'の表記が出ていればマウントがうまく行われています。\n",
    "# !ls 'drive/'\n",
    "!ls 'drive/My Drive/jupyter/ProbSpace/ukiyoe/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P15LTIMYm3-m"
   },
   "outputs": [],
   "source": [
    "##-- Google Colabでインストールされているパッケージの確認\n",
    "import pip\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3TNKtcYAY8R"
   },
   "outputs": [],
   "source": [
    "##-- import library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "##-- Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "##-- Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174303,
     "status": "ok",
     "timestamp": 1578885187875,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "Rw8YQv0DQw9Y",
    "outputId": "de4f69c8-4ede-4bd6-84df-db864de7e4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 41kB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 54.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 25.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (42.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
      "  Found existing installation: google-auth 1.4.2\n",
      "    Uninstalling google-auth-1.4.2:\n",
      "      Successfully uninstalled google-auth-1.4.2\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "Successfully installed google-auth-1.10.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/5e/e2107f55db0c122097679dba56cd795d4746a277683efe9f1f34a1b8830b/tf_nightly-2.2.0.dev20200112-cp36-cp36m-manylinux2010_x86_64.whl (449.5MB)\n",
      "\u001b[K     |████████████████████████████████| 449.5MB 15kB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 29kB/s \n",
      "\u001b[?25hCollecting gast==0.3.2\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
      "Collecting tf-estimator-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/10/5cb90983a9b395c461bd372d39b0a54e9a73f437b2411d9e2d9c94a760d9/tf_estimator_nightly-2.0.0.dev2020011209-py2.py3-none-any.whl (453kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 69.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
      "Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/32/0379b65809c879b75a736f667c01cc59a9a0c8d760670b04a12b62078388/tb_nightly-2.2.0a20200106-py3-none-any.whl (3.9MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 61.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tf-nightly) (42.0.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.21.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.3.2-cp36-none-any.whl size=9679 sha256=143135f1ba2c072479d0cfbbb02658fe072d2713463e3c971bd1f742ed5a9435\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tb-nightly 2.2.0a20200106 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: h5py, gast, tf-estimator-nightly, tb-nightly, tf-nightly\n",
      "  Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "Successfully installed gast-0.3.2 h5py-2.10.0 tb-nightly-2.2.0a20200106 tf-estimator-nightly-2.0.0.dev2020011209 tf-nightly-2.2.0.dev20200112\n"
     ]
    }
   ],
   "source": [
    "##-- Updata tensorflow 1.x -->  2.x\n",
    "# For the current version: \n",
    "# !pip install --upgrade tensorflow\n",
    "\n",
    "!pip install tensorflow-gpu \n",
    "!pip install tf-nightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 180826,
     "status": "ok",
     "timestamp": 1578885197006,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iB9Vw8gFTq6R",
    "outputId": "97cb0c26-5e5c-407b-f2f0-e167e6ebd7f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200112\n",
      "float32\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.floatx())\n",
    "print(tf.test.gpu_device_name())\n",
    "# tf.keras.backend.set_floatx(\"float16\")\n",
    "# print(tf.keras.backend.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMkVWI3QW0lF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 225926,
     "status": "ok",
     "timestamp": 1578885242717,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "edH8CExNAXkX",
    "outputId": "cde08e0f-b3d3-4d4a-93aa-84b78a6b88a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  Data PATH  ---###\n",
    "datapath = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/data_kfold/\"\n",
    "\n",
    "###------------------------------------------------------------------###\n",
    "###       EDIT!!!, when you change the model       ###\n",
    "###------------------------------------------------------------------###\n",
    "###-- Read Data\n",
    "filename_train = \"ukiyoe-dataset_kfold2_train.npz\"\n",
    "filename_validation = \"ukiyoe-dataset_kfold2_validation.npz\"\n",
    "\n",
    "X_train = np.load(datapath+filename_train)[\"img\"]\n",
    "Y_train = np.load(datapath+filename_train)[\"lbl\"]\n",
    "X_test = np.load(datapath+filename_validation)[\"img\"]\n",
    "Y_test = np.load(datapath+filename_validation)[\"lbl\"]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 229265,
     "status": "ok",
     "timestamp": 1578885247874,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "mazkt_NQ-j_3",
    "outputId": "e77556b6-525a-40c0-e87e-7ea19f267ee6"
   },
   "outputs": [],
   "source": [
    "print(Y_train[0])\n",
    "print(X_train[3][0].shape)\n",
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[22], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2Co2pj3nogh"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###       Cutout Random Erasing       ###\n",
    "###-----------------------------------###\n",
    "###-- Rondom Erasing --###\n",
    "def eraser(input_img):\n",
    "    ##-- Parameter\n",
    "    p=0.5\n",
    "    s_l=0.02\n",
    "    s_h=0.4\n",
    "    r_1=0.3\n",
    "    r_2=1/0.3\n",
    "    v_l=0\n",
    "#     v_h=255\n",
    "    v_h=1\n",
    "    pixel_level=False\n",
    "    ##--\n",
    "    img_h, img_w, img_c = input_img.shape\n",
    "    p_1 = np.random.rand()\n",
    "\n",
    "    if p_1 > p:\n",
    "        return input_img\n",
    "\n",
    "    while True:\n",
    "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "        r = np.random.uniform(r_1, r_2)\n",
    "        w = int(np.sqrt(s / r))\n",
    "        h = int(np.sqrt(s * r))\n",
    "        left = np.random.randint(0, img_w)\n",
    "        top = np.random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            break\n",
    "\n",
    "    if pixel_level:\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "    else:\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "    input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "    return input_img\n",
    "  \n",
    "###-------------------------------------###\n",
    "###-- Batch dealing of Random Erasing --###\n",
    "###-------------------------------------###\n",
    "def RandomErase( img_train ):\n",
    "  x = []\n",
    "  for i in range( len(img_train) ):\n",
    "    tem = eraser( img_train[i] )\n",
    "    x.append( tem )\n",
    "    \n",
    "  x = np.array(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 227977,
     "status": "ok",
     "timestamp": 1578885249404,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MPOcYeaInsKM",
    "outputId": "8a8ccc69-3974-4d2b-c3e1-56e6bc49f865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###-- Cutout Random Erasing --##\n",
    "X_train = RandomErase( X_train )\n",
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 227276,
     "status": "ok",
     "timestamp": 1578885249405,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "2U7kKeRW9SfS",
    "outputId": "0e664243-4169-4c86-95a2-03c8d70ac3b3"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[3], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_t7gxSc3xgx5"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###         Data Augmentation         ###\n",
    "###-----------------------------------###\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy.random import randint\n",
    "\n",
    "##--(Number of data, Height, Width, Channels) \n",
    "def Data_Augmentation(image):\n",
    "  ######################################\n",
    "  ###-- Set augmentation generator --###\n",
    "  ######################################\n",
    "  ##-- Rondom flip\n",
    "  rotation = ImageDataGenerator(rotation_range=20)\n",
    "  ##-- Parallel Movement align to vertical direction.\n",
    "  shift_vertical = ImageDataGenerator(height_shift_range=0.2)\n",
    "  ##-- Parallel Movement align to horizontal direction.\n",
    "  shift_horizontal = ImageDataGenerator(width_shift_range=0.2)\n",
    "  ##-- Shear transformation; shera_range describes \"angle\".\n",
    "  shear = ImageDataGenerator(shear_range=5)\n",
    "  ##-- [-5.0, 5.0] の範囲でランダムに画素値に値を足す。\n",
    "  noise = ImageDataGenerator(channel_shift_range=5.)\n",
    "  ##-- [0.3, 1.0] の範囲でランダムに明度を変更する。\n",
    "  brightness = ImageDataGenerator(brightness_range=[0.3, 1.0])\n",
    "  ##--\n",
    "  ret = []\n",
    "  for i in range( 0, len(image) ):\n",
    "    tem_img = np.reshape(image[i], [-1, image[i].shape[0], image[i].shape[1], image[i].shape[2]])\n",
    "    ##-- Create random number between 0 - 3.\n",
    "    rand_int = randint(4)\n",
    "    if rand_int == 0:\n",
    "      img_rot = rotation.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 1:\n",
    "      img_rot = shift_vertical.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 2:\n",
    "      img_rot = shift_horizontal.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 3:\n",
    "      img_rot = shear.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = noise.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 5:\n",
    "    #   img_rot = brightness.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = tem_img\n",
    "    # #--\n",
    "    # img_rot = next(img_rot)\n",
    "    # #--\n",
    "    ret.append( img_rot[0] )\n",
    "\n",
    "  ret = np.array( ret )\n",
    "  \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262153,
     "status": "ok",
     "timestamp": 1578885287602,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "cqyFRUxr2GYg",
    "outputId": "29fbbb6d-c59f-452f-d20c-ec064629a935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5408, 224, 224, 3)\n",
      "(5408, 10)\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------###\n",
    "###         Data Augmentation and Inflation         ###\n",
    "###-------------------------------------------------###\n",
    "import gc\n",
    "\n",
    "multiple = 1\n",
    "img_ori = X_train.copy()\n",
    "lbl_ori = Y_train.copy()\n",
    "for i in range( multiple ):\n",
    "  data_tem = Data_Augmentation( img_ori )\n",
    "  X_train = np.append( X_train, data_tem, axis=0 )\n",
    "  Y_train = np.append( Y_train, lbl_ori, axis=0 )\n",
    "\n",
    "del img_ori, lbl_ori\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 260606,
     "status": "ok",
     "timestamp": 1578885287604,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "QTjoNisT2AK5",
    "outputId": "f420cf23-4882-48f4-c247-97c393167792"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[458], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 261440,
     "status": "ok",
     "timestamp": 1578885289941,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "I005dRcTpLrf",
    "outputId": "301b1682-01af-4aff-c6a8-b86a73667e49"
   },
   "outputs": [],
   "source": [
    "###-- See several image --###\n",
    "cols, rows = 5, 4\n",
    "img_num = cols * rows\n",
    "\n",
    "for i in range(img_num):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(X_train[i], cmap=cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw4GaBn8LJhB"
   },
   "outputs": [],
   "source": [
    "###-- Shuffle dataset --###\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9NYNSLba5wm"
   },
   "source": [
    "###---  Definition of each Model  ---###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLtmtymFacU4"
   },
   "source": [
    "学習およびモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2833,
     "status": "ok",
     "timestamp": 1578889569187,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "jf4HO34XxyMB",
    "outputId": "be6a5d03-e05e-4431-875d-d5eaf7b52aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_21[0][0]           \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_22[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_23[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 10)           20490       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 23,539,850\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##-- Select the Model\n",
    "# model = ZeroDL(_input_shape=(224, 224, 3), num_classes=num_classes)\n",
    "# model = build_model(_input_shape=(224, 224, 3), num_classes=num_classes)  #--lr=0.0005 + Adam + epoch100-150\n",
    "\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "model = tf.keras.applications.ResNet50V2(\n",
    "# model = tf.keras.applications.ResNet101(\n",
    "# model = tf.keras.applications.ResNet152(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,  #--\"max\" is global max pooling, None is ordinary max pooling\n",
    "    classes=10\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 642456,
     "status": "ok",
     "timestamp": 1578890211957,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "x75E1XijCzGl",
    "outputId": "1143e322-3a58-447a-b5f1-7d42a0381d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 5408 samples, validate on 676 samples\n",
      "Epoch 1/25\n",
      "5408/5408 - 31s - loss: 1.9059 - accuracy: 0.3158 - val_loss: 2.4153 - val_accuracy: 0.1243\n",
      "Epoch 2/25\n",
      "5408/5408 - 25s - loss: 1.5134 - accuracy: 0.4654 - val_loss: 2.9166 - val_accuracy: 0.1243\n",
      "Epoch 3/25\n",
      "5408/5408 - 25s - loss: 1.3279 - accuracy: 0.5266 - val_loss: 3.0158 - val_accuracy: 0.1775\n",
      "Epoch 4/25\n",
      "5408/5408 - 25s - loss: 1.2105 - accuracy: 0.5640 - val_loss: 2.3767 - val_accuracy: 0.2470\n",
      "Epoch 5/25\n",
      "5408/5408 - 25s - loss: 1.1102 - accuracy: 0.6085 - val_loss: 1.3187 - val_accuracy: 0.5148\n",
      "Epoch 6/25\n",
      "5408/5408 - 25s - loss: 1.0160 - accuracy: 0.6498 - val_loss: 1.4344 - val_accuracy: 0.5089\n",
      "Epoch 7/25\n",
      "5408/5408 - 25s - loss: 0.9277 - accuracy: 0.6810 - val_loss: 1.5165 - val_accuracy: 0.4453\n",
      "Epoch 8/25\n",
      "5408/5408 - 25s - loss: 0.8401 - accuracy: 0.7132 - val_loss: 1.1649 - val_accuracy: 0.5754\n",
      "Epoch 9/25\n",
      "5408/5408 - 25s - loss: 0.7500 - accuracy: 0.7541 - val_loss: 1.3919 - val_accuracy: 0.5488\n",
      "Epoch 10/25\n",
      "5408/5408 - 25s - loss: 0.6742 - accuracy: 0.7788 - val_loss: 1.3202 - val_accuracy: 0.6021\n",
      "Epoch 11/25\n",
      "5408/5408 - 25s - loss: 0.5956 - accuracy: 0.8116 - val_loss: 1.4245 - val_accuracy: 0.5976\n",
      "Epoch 12/25\n",
      "5408/5408 - 25s - loss: 0.5230 - accuracy: 0.8317 - val_loss: 0.9149 - val_accuracy: 0.7071\n",
      "Epoch 13/25\n",
      "5408/5408 - 25s - loss: 0.4592 - accuracy: 0.8576 - val_loss: 1.2462 - val_accuracy: 0.6391\n",
      "Epoch 14/25\n",
      "5408/5408 - 25s - loss: 0.3923 - accuracy: 0.8820 - val_loss: 1.2258 - val_accuracy: 0.6420\n",
      "Epoch 15/25\n",
      "5408/5408 - 25s - loss: 0.3159 - accuracy: 0.9087 - val_loss: 1.0159 - val_accuracy: 0.6967\n",
      "Epoch 16/25\n",
      "5408/5408 - 25s - loss: 0.2729 - accuracy: 0.9275 - val_loss: 1.0997 - val_accuracy: 0.6790\n",
      "Epoch 17/25\n",
      "5408/5408 - 25s - loss: 0.2254 - accuracy: 0.9423 - val_loss: 1.0994 - val_accuracy: 0.6923\n",
      "Epoch 18/25\n",
      "5408/5408 - 25s - loss: 0.1887 - accuracy: 0.9538 - val_loss: 1.3208 - val_accuracy: 0.6627\n",
      "Epoch 19/25\n",
      "5408/5408 - 25s - loss: 0.1731 - accuracy: 0.9580 - val_loss: 1.5675 - val_accuracy: 0.6065\n",
      "Epoch 20/25\n",
      "5408/5408 - 25s - loss: 0.1425 - accuracy: 0.9638 - val_loss: 1.3919 - val_accuracy: 0.6672\n",
      "Epoch 21/25\n",
      "5408/5408 - 25s - loss: 0.1011 - accuracy: 0.9795 - val_loss: 1.3762 - val_accuracy: 0.6657\n",
      "Epoch 22/25\n",
      "5408/5408 - 25s - loss: 0.0812 - accuracy: 0.9858 - val_loss: 0.9615 - val_accuracy: 0.7500\n",
      "Epoch 23/25\n",
      "5408/5408 - 25s - loss: 0.0665 - accuracy: 0.9887 - val_loss: 0.9305 - val_accuracy: 0.7692\n",
      "Epoch 24/25\n",
      "5408/5408 - 25s - loss: 0.0470 - accuracy: 0.9948 - val_loss: 1.2365 - val_accuracy: 0.7115\n",
      "Epoch 25/25\n",
      "5408/5408 - 25s - loss: 0.0542 - accuracy: 0.9915 - val_loss: 0.9716 - val_accuracy: 0.7692\n"
     ]
    }
   ],
   "source": [
    "##-- Define the optimizer\n",
    "from tensorflow.keras import optimizers, losses\n",
    "optimizer = optimizers.SGD(lr = 0.001, #--lr=0.01\n",
    "                           momentum = 0.9, #--Default: 0.9\n",
    "                           nesterov = True #--Default: False\n",
    "                           )\n",
    "# optimizer = optimizers.RMSprop(lr=0.001, rho=0.99)\n",
    "# optimizer = optimizers.Adam(lr=0.0005)\n",
    "# optimizer = optimizers.Adam(lr=0.01,\n",
    "#                             # beta_1=0.9, beta_2=0.999, #--Defoalt values\n",
    "#                             # amsgrad=True, #--AMSGrad\n",
    "#                             )\n",
    "##-- Compile the model\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 64 #-- Default: 128, 64, 32\n",
    "##-- Early stopping as es\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
    "##-- Temporary save\n",
    "#--Ref. :  https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ja\n",
    "import os\n",
    "#-- ファイル名に(`str.format`を使って)エポック数を埋め込みます\n",
    "checkpoint_path = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/check_point/model2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # 重みを5エポックごとに保存します\n",
    "    period=5)  #--period\n",
    "##-- Run\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (X_test,Y_test), #-- validation_split=0.2\n",
    "                    verbose=2, \n",
    "                    # callbacks = [cp_callback]\n",
    "                    # callbacks = [es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1578890328813,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iT8BX58kDM17",
    "outputId": "7687d04c-7845-4abb-d7d6-fa370f2c7f5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD7CAYAAACIYvgKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSvFUSaz1bmM"
   },
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3i8JbBY1ZwT"
   },
   "outputs": [],
   "source": [
    "###------------------------------------------------------------------###\n",
    "###       EDIT!!!, when you change the model       ###\n",
    "###------------------------------------------------------------------###\n",
    "###-- モデル全体を１つのHDF5ファイルに保存します。\n",
    "datapath_model = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/save_model/\"\n",
    "model.save(datapath_model+'model2.h5')\n",
    "\n",
    "###-- Load model file\n",
    "# model = tf.keras.models.load_model('model1.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf5wp7TujyCN"
   },
   "source": [
    "検証データで精度チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbvZB6wdjnJD"
   },
   "source": [
    "テストデータで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1990,
     "status": "ok",
     "timestamp": 1577941877917,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "pvU-d5tlZpFf",
    "outputId": "4f8b162e-98b5-4f20-de73-e265734df4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  提出用データの読み込み  ---###\n",
    "\n",
    "###--データの読み込み\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "X_submit = load(datapath+\"ukiyoe-test-imgs.npz\")\n",
    "\n",
    "###--型をint --> float変換する。\n",
    "X_submit = X_submit.astype(np.float32)\n",
    "###-- convert from [0:255] => [0.0:1.0]\n",
    "X_submit = np.multiply(X_submit, 1.0 / 255.0)\n",
    "\n",
    "print(X_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1577941891751,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "_SJK37dOgBfC",
    "outputId": "6058c09b-aeaf-426a-e2f2-4eade36da54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###---  Prediction  ---###\n",
    "predicts = np.argmax(model.predict(X_submit), axis=1)\n",
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1577941895012,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "rU8_tPMIfxh8",
    "outputId": "ca988305-34ee-404f-8105-09e62b96b612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  y\n",
      "0   1  4\n",
      "1   2  1\n",
      "2   3  3\n",
      "3   4  1\n",
      "4   5  1\n"
     ]
    }
   ],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "\n",
    "submit = pd.DataFrame(data={\"id\": [], \"y\": []})\n",
    "submit.id = list(range(1, predicts.shape[0]+1))\n",
    "submit.y = predicts\n",
    "submit.to_csv(\"submit.csv\", index=False)\n",
    "\n",
    "print(submit.head())\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8Cl8nPVfx0s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432250,
     "status": "ok",
     "timestamp": 1560433030328,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "GEAK9h1GXt8R",
    "outputId": "478c024e-a882-4dbf-9e6b-812ebf80cf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 3 ... 9 4 2]\n"
     ]
    }
   ],
   "source": [
    "###--- テストデータでテスト ---#\n",
    "##-- N = 10000; Number of test images\n",
    "i = 0\n",
    "N = 10000\n",
    "predicts = []\n",
    "while i < N:\n",
    "    i = i + 100\n",
    "    ##--\n",
    "    tem = []\n",
    "    tem_1 = []\n",
    "    tem_2 = []\n",
    "    tem_3 = []\n",
    "    tem_4 = []\n",
    "    tem_5 = []\n",
    "    ##--\n",
    "    #tem_1 = model_1.predict(test_imgs[i-100:i])\n",
    "    tem_2 = model_2.predict(test_imgs[i-100:i])\n",
    "    tem_3 = model_3.predict(test_imgs[i-100:i])\n",
    "    tem_4 = model_4.predict(test_imgs[i-100:i])\n",
    "    tem_5 = model_5.predict(test_imgs[i-100:i])\n",
    "    #tem = tem_1 + tem_2 + tem_3 + tem_4 + tem_5\n",
    "    tem = tem_2 + tem_3 + tem_4 + tem_5\n",
    "    ##--\n",
    "    predicts = np.append( predicts, np.argmax( tem , axis=1) )\n",
    "  \n",
    "predicts = predicts.astype(np.int64)\n",
    "\n",
    "predicts.shape\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "error",
     "timestamp": 1577603913673,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "FCH4zL-9dPQo",
    "outputId": "6a1ea8bd-acd8-4080-f8b6-293de81adbda"
   },
   "outputs": [],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "###-- 変数predictsに予測結果を入れて下さい\n",
    "###-- 型はnumpy.ndarrayで\n",
    "###-- shapeは(10000,)になるはずです\n",
    "###-- predicts = \n",
    "submit = pd.DataFrame(data={\"ImageId\": [], \"Label\": []})\n",
    "\n",
    "submit.ImageId = list(range(1, predicts.shape[0]+1))\n",
    "submit.Label = predicts\n",
    "\n",
    "submit.to_csv(root.joinpath(\"submit.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lbeDsG67hlH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_model2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

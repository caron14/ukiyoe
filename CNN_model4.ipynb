{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16419,
     "status": "ok",
     "timestamp": 1578846727292,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MKIvjGGMAFg4",
    "outputId": "4c728181-6c21-4117-dbc3-0ea6512e867e"
   },
   "outputs": [],
   "source": [
    "###  Rer.\n",
    "#-- https://www.kaggle.com/luyujia/mnist-chainer-cnn/notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3302,
     "status": "ok",
     "timestamp": 1578846732165,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "LQXnyzGwAlVt",
    "outputId": "da6ce0ec-ee0f-4f62-ac8b-c702452ae2c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukiyoe-test-imgs.npz  ukiyoe-train-imgs.npz  ukiyoe-train-labels.npz\n"
     ]
    }
   ],
   "source": [
    "# 'My Drive'の表記が出ていればマウントがうまく行われています。\n",
    "# !ls 'drive/'\n",
    "!ls 'drive/My Drive/jupyter/ProbSpace/ukiyoe/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P15LTIMYm3-m"
   },
   "outputs": [],
   "source": [
    "##-- Google Colabでインストールされているパッケージの確認\n",
    "import pip\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3TNKtcYAY8R"
   },
   "outputs": [],
   "source": [
    "##-- import library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "##-- Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "##-- Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 175398,
     "status": "ok",
     "timestamp": 1578846913436,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "Rw8YQv0DQw9Y",
    "outputId": "0bdb89e5-a7ed-4dba-eed2-c9fd15519019"
   },
   "outputs": [],
   "source": [
    "##-- Updata tensorflow 1.x -->  2.x\n",
    "# For the current version: \n",
    "# !pip install --upgrade tensorflow\n",
    "\n",
    "!pip install tensorflow-gpu \n",
    "!pip install tf-nightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 180019,
     "status": "ok",
     "timestamp": 1578846922524,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iB9Vw8gFTq6R",
    "outputId": "05ab61b2-0e73-4169-f46b-8e34d605fb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200112\n",
      "float32\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.floatx())\n",
    "print(tf.test.gpu_device_name())\n",
    "# tf.keras.backend.set_floatx(\"float16\")\n",
    "# print(tf.keras.backend.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMkVWI3QW0lF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 224110,
     "status": "ok",
     "timestamp": 1578846967394,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "edH8CExNAXkX",
    "outputId": "d2d27909-c818-40ae-9f8e-0f0706c3e4f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  Data PATH  ---###\n",
    "datapath = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/data_kfold/\"\n",
    "\n",
    "###------------------------------------------------------------------###\n",
    "###       EDIT!!!, when you change the model       ###\n",
    "###------------------------------------------------------------------###\n",
    "###-- Read Data\n",
    "filename_train = \"ukiyoe-dataset_kfold4_train.npz\"\n",
    "filename_validation = \"ukiyoe-dataset_kfold4_validation.npz\"\n",
    "\n",
    "X_train = np.load(datapath+filename_train)[\"img\"]\n",
    "Y_train = np.load(datapath+filename_train)[\"lbl\"]\n",
    "X_test = np.load(datapath+filename_validation)[\"img\"]\n",
    "Y_test = np.load(datapath+filename_validation)[\"lbl\"]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 229099,
     "status": "ok",
     "timestamp": 1578846972762,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "mazkt_NQ-j_3",
    "outputId": "f27bd3ea-6588-4923-940b-acfdb5920259"
   },
   "outputs": [],
   "source": [
    "print(Y_train[0])\n",
    "print(X_train[3][0].shape)\n",
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[22], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2Co2pj3nogh"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###       Cutout Random Erasing       ###\n",
    "###-----------------------------------###\n",
    "###-- Rondom Erasing --###\n",
    "def eraser(input_img):\n",
    "    ##-- Parameter\n",
    "    p=0.5\n",
    "    s_l=0.02\n",
    "    s_h=0.4\n",
    "    r_1=0.3\n",
    "    r_2=1/0.3\n",
    "    v_l=0\n",
    "#     v_h=255\n",
    "    v_h=1\n",
    "    pixel_level=False\n",
    "    ##--\n",
    "    img_h, img_w, img_c = input_img.shape\n",
    "    p_1 = np.random.rand()\n",
    "\n",
    "    if p_1 > p:\n",
    "        return input_img\n",
    "\n",
    "    while True:\n",
    "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "        r = np.random.uniform(r_1, r_2)\n",
    "        w = int(np.sqrt(s / r))\n",
    "        h = int(np.sqrt(s * r))\n",
    "        left = np.random.randint(0, img_w)\n",
    "        top = np.random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            break\n",
    "\n",
    "    if pixel_level:\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "    else:\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "    input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "    return input_img\n",
    "  \n",
    "###-------------------------------------###\n",
    "###-- Batch dealing of Random Erasing --###\n",
    "###-------------------------------------###\n",
    "def RandomErase( img_train ):\n",
    "  x = []\n",
    "  for i in range( len(img_train) ):\n",
    "    tem = eraser( img_train[i] )\n",
    "    x.append( tem )\n",
    "    \n",
    "  x = np.array(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 229002,
     "status": "ok",
     "timestamp": 1578846974401,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MPOcYeaInsKM",
    "outputId": "ae80201d-9811-442b-a448-c16b6da2b3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###-- Cutout Random Erasing --##\n",
    "X_train = RandomErase( X_train )\n",
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 228781,
     "status": "ok",
     "timestamp": 1578846974402,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "2U7kKeRW9SfS",
    "outputId": "45fa65f4-18b3-4ee8-8c86-503769dbf1ac"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[3], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_t7gxSc3xgx5"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###         Data Augmentation         ###\n",
    "###-----------------------------------###\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy.random import randint\n",
    "\n",
    "##--(Number of data, Height, Width, Channels) \n",
    "def Data_Augmentation(image):\n",
    "  ######################################\n",
    "  ###-- Set augmentation generator --###\n",
    "  ######################################\n",
    "  ##-- Rondom flip\n",
    "  rotation = ImageDataGenerator(rotation_range=20)\n",
    "  ##-- Parallel Movement align to vertical direction.\n",
    "  shift_vertical = ImageDataGenerator(height_shift_range=0.2)\n",
    "  ##-- Parallel Movement align to horizontal direction.\n",
    "  shift_horizontal = ImageDataGenerator(width_shift_range=0.2)\n",
    "  ##-- Shear transformation; shera_range describes \"angle\".\n",
    "  shear = ImageDataGenerator(shear_range=5)\n",
    "  ##-- [-5.0, 5.0] の範囲でランダムに画素値に値を足す。\n",
    "  noise = ImageDataGenerator(channel_shift_range=5.)\n",
    "  ##-- [0.3, 1.0] の範囲でランダムに明度を変更する。\n",
    "  brightness = ImageDataGenerator(brightness_range=[0.3, 1.0])\n",
    "  ##--\n",
    "  ret = []\n",
    "  for i in range( 0, len(image) ):\n",
    "    tem_img = np.reshape(image[i], [-1, image[i].shape[0], image[i].shape[1], image[i].shape[2]])\n",
    "    ##-- Create random number between 0 - 3.\n",
    "    rand_int = randint(4)\n",
    "    if rand_int == 0:\n",
    "      img_rot = rotation.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 1:\n",
    "      img_rot = shift_vertical.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 2:\n",
    "      img_rot = shift_horizontal.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 3:\n",
    "      img_rot = shear.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = noise.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 5:\n",
    "    #   img_rot = brightness.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = tem_img\n",
    "    # #--\n",
    "    # img_rot = next(img_rot)\n",
    "    # #--\n",
    "    ret.append( img_rot[0] )\n",
    "\n",
    "  ret = np.array( ret )\n",
    "  \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 264099,
     "status": "ok",
     "timestamp": 1578847011404,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "cqyFRUxr2GYg",
    "outputId": "45273ee9-58e8-4998-fadb-dcb1a5b02340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5408, 224, 224, 3)\n",
      "(5408, 10)\n"
     ]
    }
   ],
   "source": [
    "###-------------------------------------------------###\n",
    "###         Data Augmentation and Inflation         ###\n",
    "###-------------------------------------------------###\n",
    "import gc\n",
    "\n",
    "multiple = 1\n",
    "img_ori = X_train.copy()\n",
    "lbl_ori = Y_train.copy()\n",
    "for i in range( multiple ):\n",
    "  data_tem = Data_Augmentation( img_ori )\n",
    "  X_train = np.append( X_train, data_tem, axis=0 )\n",
    "  Y_train = np.append( Y_train, lbl_ori, axis=0 )\n",
    "\n",
    "del img_ori, lbl_ori\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 262972,
     "status": "ok",
     "timestamp": 1578847011644,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "QTjoNisT2AK5",
    "outputId": "da984f6b-fe8b-4d44-ddf7-bf5be9087fd2"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[458], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 266206,
     "status": "ok",
     "timestamp": 1578847015949,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "I005dRcTpLrf",
    "outputId": "c5731abd-1c4f-4a86-cbbd-5eba4903bd76"
   },
   "outputs": [],
   "source": [
    "###-- See several image --###\n",
    "cols, rows = 5, 4\n",
    "img_num = cols * rows\n",
    "\n",
    "for i in range(img_num):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(X_train[i], cmap=cm.gray_r, interpolation=\"nearest\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw4GaBn8LJhB"
   },
   "outputs": [],
   "source": [
    "###-- Shuffle dataset --###\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9NYNSLba5wm"
   },
   "source": [
    "###---  Definition of each Model  ---###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLtmtymFacU4"
   },
   "source": [
    "学習およびモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1578849446078,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "jf4HO34XxyMB",
    "outputId": "898e8a32-cebd-41cd-c3fb-74c99fd25315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 10)           20490       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 23,539,850\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##-- Select the Model\n",
    "# model = ZeroDL(_input_shape=(224, 224, 3), num_classes=num_classes)\n",
    "# model = build_model(_input_shape=(224, 224, 3), num_classes=num_classes)  #--lr=0.0005 + Adam + epoch100-150\n",
    "\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "model = tf.keras.applications.ResNet50V2(\n",
    "# model = tf.keras.applications.ResNet101(\n",
    "# model = tf.keras.applications.ResNet152(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,  #--\"max\" is global max pooling, None is ordinary max pooling\n",
    "    classes=10\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766718,
     "status": "ok",
     "timestamp": 1578850220327,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "x75E1XijCzGl",
    "outputId": "743d20d6-3f70-4e10-cad6-da4358549fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 5408 samples, validate on 676 samples\n",
      "Epoch 1/30\n",
      "5408/5408 - 30s - loss: 1.9212 - accuracy: 0.3158 - val_loss: 2.4747 - val_accuracy: 0.1982\n",
      "Epoch 2/30\n",
      "5408/5408 - 25s - loss: 1.4612 - accuracy: 0.4867 - val_loss: 3.1126 - val_accuracy: 0.2115\n",
      "Epoch 3/30\n",
      "5408/5408 - 25s - loss: 1.2722 - accuracy: 0.5425 - val_loss: 2.9316 - val_accuracy: 0.2396\n",
      "Epoch 4/30\n",
      "5408/5408 - 25s - loss: 1.1553 - accuracy: 0.5852 - val_loss: 2.1008 - val_accuracy: 0.3195\n",
      "Epoch 5/30\n",
      "5408/5408 - 25s - loss: 1.0419 - accuracy: 0.6366 - val_loss: 1.6320 - val_accuracy: 0.4201\n",
      "Epoch 6/30\n",
      "5408/5408 - 25s - loss: 0.9386 - accuracy: 0.6823 - val_loss: 1.2016 - val_accuracy: 0.5710\n",
      "Epoch 7/30\n",
      "5408/5408 - 25s - loss: 0.8470 - accuracy: 0.7191 - val_loss: 1.1824 - val_accuracy: 0.5976\n",
      "Epoch 8/30\n",
      "5408/5408 - 25s - loss: 0.7650 - accuracy: 0.7487 - val_loss: 1.1103 - val_accuracy: 0.6198\n",
      "Epoch 9/30\n",
      "5408/5408 - 25s - loss: 0.6806 - accuracy: 0.7811 - val_loss: 1.3272 - val_accuracy: 0.6036\n",
      "Epoch 10/30\n",
      "5408/5408 - 25s - loss: 0.6169 - accuracy: 0.7988 - val_loss: 3.5571 - val_accuracy: 0.4334\n",
      "Epoch 11/30\n",
      "5408/5408 - 25s - loss: 0.5424 - accuracy: 0.8277 - val_loss: 1.2994 - val_accuracy: 0.6095\n",
      "Epoch 12/30\n",
      "5408/5408 - 25s - loss: 0.4827 - accuracy: 0.8515 - val_loss: 1.0602 - val_accuracy: 0.6849\n",
      "Epoch 13/30\n",
      "5408/5408 - 25s - loss: 0.4151 - accuracy: 0.8735 - val_loss: 1.4149 - val_accuracy: 0.5888\n",
      "Epoch 14/30\n",
      "5408/5408 - 25s - loss: 0.3703 - accuracy: 0.8898 - val_loss: 0.9759 - val_accuracy: 0.6864\n",
      "Epoch 15/30\n",
      "5408/5408 - 25s - loss: 0.2983 - accuracy: 0.9210 - val_loss: 1.1684 - val_accuracy: 0.6834\n",
      "Epoch 16/30\n",
      "5408/5408 - 25s - loss: 0.2491 - accuracy: 0.9327 - val_loss: 1.5208 - val_accuracy: 0.5814\n",
      "Epoch 17/30\n",
      "5408/5408 - 25s - loss: 0.1958 - accuracy: 0.9541 - val_loss: 0.9877 - val_accuracy: 0.7263\n",
      "Epoch 18/30\n",
      "5408/5408 - 25s - loss: 0.1702 - accuracy: 0.9584 - val_loss: 1.3328 - val_accuracy: 0.6642\n",
      "Epoch 19/30\n",
      "5408/5408 - 25s - loss: 0.1400 - accuracy: 0.9712 - val_loss: 1.3274 - val_accuracy: 0.6405\n",
      "Epoch 20/30\n",
      "5408/5408 - 25s - loss: 0.1095 - accuracy: 0.9806 - val_loss: 1.0843 - val_accuracy: 0.7071\n",
      "Epoch 21/30\n",
      "5408/5408 - 25s - loss: 0.0888 - accuracy: 0.9865 - val_loss: 1.8287 - val_accuracy: 0.6124\n",
      "Epoch 22/30\n",
      "5408/5408 - 25s - loss: 0.1028 - accuracy: 0.9797 - val_loss: 1.1854 - val_accuracy: 0.7101\n",
      "Epoch 23/30\n",
      "5408/5408 - 25s - loss: 0.0713 - accuracy: 0.9874 - val_loss: 1.1340 - val_accuracy: 0.7175\n",
      "Epoch 24/30\n",
      "5408/5408 - 25s - loss: 0.0538 - accuracy: 0.9913 - val_loss: 1.5246 - val_accuracy: 0.6686\n",
      "Epoch 25/30\n",
      "5408/5408 - 25s - loss: 0.0575 - accuracy: 0.9898 - val_loss: 0.9122 - val_accuracy: 0.7751\n",
      "Epoch 26/30\n",
      "5408/5408 - 25s - loss: 0.0476 - accuracy: 0.9922 - val_loss: 1.2765 - val_accuracy: 0.7012\n",
      "Epoch 27/30\n",
      "5408/5408 - 25s - loss: 0.0366 - accuracy: 0.9963 - val_loss: 1.5082 - val_accuracy: 0.6849\n",
      "Epoch 28/30\n",
      "5408/5408 - 25s - loss: 0.0471 - accuracy: 0.9900 - val_loss: 0.9712 - val_accuracy: 0.7648\n",
      "Epoch 29/30\n",
      "5408/5408 - 25s - loss: 0.0391 - accuracy: 0.9939 - val_loss: 1.3979 - val_accuracy: 0.6879\n",
      "Epoch 30/30\n",
      "5408/5408 - 25s - loss: 0.0295 - accuracy: 0.9961 - val_loss: 0.9610 - val_accuracy: 0.7781\n"
     ]
    }
   ],
   "source": [
    "##-- 0.7781\n",
    "\n",
    "##-- Define the optimizer\n",
    "from tensorflow.keras import optimizers, losses\n",
    "optimizer = optimizers.SGD(lr = 0.001, #--lr=0.01\n",
    "                           momentum = 0.9, #--Default: 0.9\n",
    "                           nesterov = True #--Default: False\n",
    "                           )\n",
    "# optimizer = optimizers.RMSprop(lr=0.001, rho=0.99)\n",
    "# optimizer = optimizers.Adam(lr=0.0005)\n",
    "# optimizer = optimizers.Adam(lr=0.01,\n",
    "#                             # beta_1=0.9, beta_2=0.999, #--Defoalt values\n",
    "#                             # amsgrad=True, #--AMSGrad\n",
    "#                             )\n",
    "##-- Compile the model\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64 #-- Default: 128, 64, 32\n",
    "##-- Early stopping as es\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
    "##-- Temporary save\n",
    "#--Ref. :  https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ja\n",
    "import os\n",
    "#-- ファイル名に(`str.format`を使って)エポック数を埋め込みます\n",
    "checkpoint_path = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/check_point/model3/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # 重みを5エポックごとに保存します\n",
    "    period=5)  #--period\n",
    "##-- Run\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (X_test,Y_test), #-- validation_split=0.2\n",
    "                    verbose=2, \n",
    "                    # callbacks = [cp_callback]\n",
    "                    # callbacks = [es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1578850266277,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iT8BX58kDM17",
    "outputId": "fc108e79-abf0-447f-99c1-b769d1fedc74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD7CAYAAACMlyg3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSvFUSaz1bmM"
   },
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3i8JbBY1ZwT"
   },
   "outputs": [],
   "source": [
    "###------------------------------------------------------------------###\n",
    "###       EDIT!!!, when you change the model       ###\n",
    "###------------------------------------------------------------------###\n",
    "###-- モデル全体を１つのHDF5ファイルに保存します。\n",
    "datapath_model = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/save_model/\"\n",
    "model.save(datapath_model+'model4.h5')\n",
    "\n",
    "###-- Load model file\n",
    "# model = tf.keras.models.load_model('model4.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf5wp7TujyCN"
   },
   "source": [
    "検証データで精度チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbvZB6wdjnJD"
   },
   "source": [
    "テストデータで予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1990,
     "status": "ok",
     "timestamp": 1577941877917,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "pvU-d5tlZpFf",
    "outputId": "4f8b162e-98b5-4f20-de73-e265734df4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  提出用データの読み込み  ---###\n",
    "\n",
    "###--データの読み込み\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "X_submit = load(datapath+\"ukiyoe-test-imgs.npz\")\n",
    "\n",
    "###--型をint --> float変換する。\n",
    "X_submit = X_submit.astype(np.float32)\n",
    "###-- convert from [0:255] => [0.0:1.0]\n",
    "X_submit = np.multiply(X_submit, 1.0 / 255.0)\n",
    "\n",
    "print(X_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1577941891751,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "_SJK37dOgBfC",
    "outputId": "6058c09b-aeaf-426a-e2f2-4eade36da54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###---  Prediction  ---###\n",
    "predicts = np.argmax(model.predict(X_submit), axis=1)\n",
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1577941895012,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "rU8_tPMIfxh8",
    "outputId": "ca988305-34ee-404f-8105-09e62b96b612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  y\n",
      "0   1  4\n",
      "1   2  1\n",
      "2   3  3\n",
      "3   4  1\n",
      "4   5  1\n"
     ]
    }
   ],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "\n",
    "submit = pd.DataFrame(data={\"id\": [], \"y\": []})\n",
    "submit.id = list(range(1, predicts.shape[0]+1))\n",
    "submit.y = predicts\n",
    "submit.to_csv(\"submit.csv\", index=False)\n",
    "\n",
    "print(submit.head())\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432250,
     "status": "ok",
     "timestamp": 1560433030328,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "GEAK9h1GXt8R",
    "outputId": "478c024e-a882-4dbf-9e6b-812ebf80cf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 3 ... 9 4 2]\n"
     ]
    }
   ],
   "source": [
    "###--- テストデータでテスト ---#\n",
    "##-- N = 10000; Number of test images\n",
    "i = 0\n",
    "N = 10000\n",
    "predicts = []\n",
    "while i < N:\n",
    "    i = i + 100\n",
    "    ##--\n",
    "    tem = []\n",
    "    tem_1 = []\n",
    "    tem_2 = []\n",
    "    tem_3 = []\n",
    "    tem_4 = []\n",
    "    tem_5 = []\n",
    "    ##--\n",
    "    #tem_1 = model_1.predict(test_imgs[i-100:i])\n",
    "    tem_2 = model_2.predict(test_imgs[i-100:i])\n",
    "    tem_3 = model_3.predict(test_imgs[i-100:i])\n",
    "    tem_4 = model_4.predict(test_imgs[i-100:i])\n",
    "    tem_5 = model_5.predict(test_imgs[i-100:i])\n",
    "    #tem = tem_1 + tem_2 + tem_3 + tem_4 + tem_5\n",
    "    tem = tem_2 + tem_3 + tem_4 + tem_5\n",
    "    ##--\n",
    "    predicts = np.append( predicts, np.argmax( tem , axis=1) )\n",
    "  \n",
    "predicts = predicts.astype(np.int64)\n",
    "\n",
    "predicts.shape\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "error",
     "timestamp": 1577603913673,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "FCH4zL-9dPQo",
    "outputId": "6a1ea8bd-acd8-4080-f8b6-293de81adbda"
   },
   "outputs": [],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "import pandas as pd\n",
    "###-- 変数predictsに予測結果を入れて下さい\n",
    "###-- 型はnumpy.ndarrayで\n",
    "###-- shapeは(10000,)になるはずです\n",
    "###-- predicts = \n",
    "submit = pd.DataFrame(data={\"ImageId\": [], \"Label\": []})\n",
    "\n",
    "submit.ImageId = list(range(1, predicts.shape[0]+1))\n",
    "submit.Label = predicts\n",
    "\n",
    "submit.to_csv(root.joinpath(\"submit.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lbeDsG67hlH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_model4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

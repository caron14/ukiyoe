{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1578901527141,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MKIvjGGMAFg4",
    "outputId": "01960a79-6bc9-4fe7-d375-6d0239818bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "###-- Mount to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3TNKtcYAY8R"
   },
   "outputs": [],
   "source": [
    "##-- import library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "##-- Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "##-- Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177755,
     "status": "ok",
     "timestamp": 1578901723267,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "Rw8YQv0DQw9Y",
    "outputId": "c7acffba-e038-471d-8bf8-9a6227bf4ff2"
   },
   "outputs": [],
   "source": [
    "##-- Updata tensorflow 1.x -->  2.x\n",
    "# For the current version: \n",
    "# !pip install --upgrade tensorflow\n",
    "\n",
    "!pip install tensorflow-gpu \n",
    "!pip install tf-nightly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177052,
     "status": "ok",
     "timestamp": 1578901731765,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iB9Vw8gFTq6R",
    "outputId": "ff7928ed-04b0-4a83-8903-bef5e7eae495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200112\n",
      "float32\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "print(tf.__version__)\n",
    "print(tf.keras.backend.floatx())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 211655,
     "status": "ok",
     "timestamp": 1578901777714,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "edH8CExNAXkX",
    "outputId": "2a38012d-34a2-4508-bca0-a8830e231fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  Data PATH  ---###\n",
    "datapath = \"drive/My Drive/data_kfold/\"\n",
    "\n",
    "###-- Read Data\n",
    "filename_train = \"ukiyoe-dataset_kfold3_train.npz\"\n",
    "filename_validation = \"ukiyoe-dataset_kfold3_validation.npz\"\n",
    "\n",
    "X_train = np.load(datapath+filename_train)[\"img\"]\n",
    "Y_train = np.load(datapath+filename_train)[\"lbl\"]\n",
    "X_test = np.load(datapath+filename_validation)[\"img\"]\n",
    "Y_test = np.load(datapath+filename_validation)[\"lbl\"]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 211217,
     "status": "ok",
     "timestamp": 1578901782324,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "mazkt_NQ-j_3",
    "outputId": "16de1d87-d770-4137-f9b6-84117d028f1b"
   },
   "outputs": [],
   "source": [
    "print(Y_train[0])\n",
    "print(X_train[3][0].shape)\n",
    "##-- check image (Error is occured, \"np.float16\")\n",
    "plt.imshow(X_train[22], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2Co2pj3nogh"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###       Cutout Random Erasing       ###\n",
    "###-----------------------------------###\n",
    "###-- Rondom Erasing --###\n",
    "def eraser(input_img):\n",
    "    ##-- Parameter\n",
    "    p=0.5\n",
    "    s_l=0.02\n",
    "    s_h=0.4\n",
    "    r_1=0.3\n",
    "    r_2=1/0.3\n",
    "    v_l=0\n",
    "    # v_h=255\n",
    "    v_h=1\n",
    "    pixel_level=False\n",
    "    ##--\n",
    "    img_h, img_w, img_c = input_img.shape\n",
    "    p_1 = np.random.rand()\n",
    "\n",
    "    if p_1 > p:\n",
    "        return input_img\n",
    "\n",
    "    while True:\n",
    "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "        r = np.random.uniform(r_1, r_2)\n",
    "        w = int(np.sqrt(s / r))\n",
    "        h = int(np.sqrt(s * r))\n",
    "        left = np.random.randint(0, img_w)\n",
    "        top = np.random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            break\n",
    "\n",
    "    if pixel_level:\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "    else:\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "    input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "    return input_img\n",
    "  \n",
    "\"\"\"\n",
    "    Batch dealing of Random Erasing\n",
    "\"\"\"\n",
    "def RandomErase( img_train ):\n",
    "  x = []\n",
    "  for i in range( len(img_train) ):\n",
    "    tem = eraser( img_train[i] )\n",
    "    x.append( tem )\n",
    "    \n",
    "  x = np.array(x)\n",
    "  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 208511,
     "status": "ok",
     "timestamp": 1578901784484,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "MPOcYeaInsKM",
    "outputId": "fd19b63d-451b-4a5f-c4f6-3d3deca99ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2704, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###-- Cutout Random Erasing --##\n",
    "X_train = RandomErase( X_train )\n",
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 206947,
     "status": "ok",
     "timestamp": 1578901784486,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "2U7kKeRW9SfS",
    "outputId": "f28ffbb4-1f61-47e1-ae03-95a8f630ad71"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[3], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_t7gxSc3xgx5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Augmentation\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy.random import randint\n",
    "\n",
    "##--(Number of data, Height, Width, Channels) \n",
    "def Data_Augmentation(image):\n",
    "  \"\"\"\n",
    "      Set augmentation generator\n",
    "  \"\"\"\n",
    "  ##-- Rondom flip\n",
    "  rotation = ImageDataGenerator(rotation_range=20)\n",
    "  ##-- Parallel Movement align to vertical direction.\n",
    "  shift_vertical = ImageDataGenerator(height_shift_range=0.2)\n",
    "  ##-- Parallel Movement align to horizontal direction.\n",
    "  shift_horizontal = ImageDataGenerator(width_shift_range=0.2)\n",
    "  ##-- Shear transformation; shera_range describes \"angle\".\n",
    "  shear = ImageDataGenerator(shear_range=5)\n",
    "  ##-- [-5.0, 5.0] の範囲でランダムに画素値に値を足す。\n",
    "  noise = ImageDataGenerator(channel_shift_range=5.)\n",
    "  ##-- [0.3, 1.0] の範囲でランダムに明度を変更する。\n",
    "  brightness = ImageDataGenerator(brightness_range=[0.3, 1.0])\n",
    "  ##--\n",
    "  ret = []\n",
    "  for i in range( 0, len(image) ):\n",
    "    tem_img = np.reshape(image[i], [-1, image[i].shape[0], image[i].shape[1], image[i].shape[2]])\n",
    "    ##-- Create random number between 0 - 3.\n",
    "    rand_int = randint(4)\n",
    "    if rand_int == 0:\n",
    "      img_rot = rotation.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 1:\n",
    "      img_rot = shift_vertical.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 2:\n",
    "      img_rot = shift_horizontal.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    elif rand_int == 3:\n",
    "      img_rot = shear.flow( tem_img, batch_size=1 )\n",
    "      img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = noise.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 5:\n",
    "    #   img_rot = brightness.flow( tem_img, batch_size=1 )\n",
    "    #   img_rot = next(img_rot)\n",
    "    # elif rand_int == 4:\n",
    "    #   img_rot = tem_img\n",
    "    # #--\n",
    "    # img_rot = next(img_rot)\n",
    "    # #--\n",
    "    ret.append( img_rot[0] )\n",
    "\n",
    "  ret = np.array( ret )\n",
    "  \n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36773,
     "status": "ok",
     "timestamp": 1578902304937,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "cqyFRUxr2GYg",
    "outputId": "c8026b34-75a6-4f6a-a914-c46d6226b810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5408, 224, 224, 3)\n",
      "(5408, 10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Data Augmentation and Inflation\n",
    "\"\"\"\n",
    "import gc\n",
    "\n",
    "multiple = 1\n",
    "img_ori = X_train.copy()\n",
    "lbl_ori = Y_train.copy()\n",
    "for i in range( multiple ):\n",
    "  data_tem = Data_Augmentation( img_ori )\n",
    "  X_train = np.append( X_train, data_tem, axis=0 )\n",
    "  Y_train = np.append( Y_train, lbl_ori, axis=0 )\n",
    "\n",
    "del img_ori, lbl_ori\n",
    "gc.collect()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34567,
     "status": "ok",
     "timestamp": 1578902304939,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "QTjoNisT2AK5",
    "outputId": "7c1c20ee-9823-4c58-dbb2-fe56a81e3cee"
   },
   "outputs": [],
   "source": [
    "##-- check image (Error is occured, when using \"np.float16\")\n",
    "plt.imshow(X_train[458], cmap=cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw4GaBn8LJhB"
   },
   "outputs": [],
   "source": [
    "###-- Shuffle dataset --###\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9NYNSLba5wm"
   },
   "source": [
    "###---  Definition of each Model  ---###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLtmtymFacU4"
   },
   "source": [
    "学習およびモデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41077,
     "status": "ok",
     "timestamp": 1578902320134,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "jf4HO34XxyMB",
    "outputId": "ac701853-2784-43ea-9be3-7d61519c456c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 10)           20490       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 23,539,850\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##-- Select the Model\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "model = tf.keras.applications.ResNet50V2(\n",
    "# model = tf.keras.applications.ResNet101(\n",
    "# model = tf.keras.applications.ResNet152(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None,  #--\"max\" is global max pooling, None is ordinary max pooling\n",
    "    classes=10\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 902251,
     "status": "ok",
     "timestamp": 1578903222397,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "x75E1XijCzGl",
    "outputId": "cee46079-8d9f-4ed7-ba67-a7dfc81cf20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 5408 samples, validate on 676 samples\n",
      "Epoch 1/35\n",
      "5408/5408 - 39s - loss: 1.9467 - accuracy: 0.3190 - val_loss: 2.3714 - val_accuracy: 0.2175\n",
      "Epoch 2/35\n",
      "5408/5408 - 25s - loss: 1.4930 - accuracy: 0.4832 - val_loss: 2.9189 - val_accuracy: 0.2426\n",
      "Epoch 3/35\n",
      "5408/5408 - 25s - loss: 1.2906 - accuracy: 0.5335 - val_loss: 2.9808 - val_accuracy: 0.2973\n",
      "Epoch 4/35\n",
      "5408/5408 - 25s - loss: 1.1553 - accuracy: 0.5845 - val_loss: 1.6227 - val_accuracy: 0.4334\n",
      "Epoch 5/35\n",
      "5408/5408 - 25s - loss: 1.0558 - accuracy: 0.6317 - val_loss: 1.4679 - val_accuracy: 0.4660\n",
      "Epoch 6/35\n",
      "5408/5408 - 25s - loss: 0.9524 - accuracy: 0.6705 - val_loss: 1.0716 - val_accuracy: 0.6095\n",
      "Epoch 7/35\n",
      "5408/5408 - 25s - loss: 0.8569 - accuracy: 0.7147 - val_loss: 1.2924 - val_accuracy: 0.5828\n",
      "Epoch 8/35\n",
      "5408/5408 - 25s - loss: 0.7759 - accuracy: 0.7507 - val_loss: 1.5579 - val_accuracy: 0.5296\n",
      "Epoch 9/35\n",
      "5408/5408 - 25s - loss: 0.6812 - accuracy: 0.7779 - val_loss: 1.0826 - val_accuracy: 0.6435\n",
      "Epoch 10/35\n",
      "5408/5408 - 25s - loss: 0.6112 - accuracy: 0.8081 - val_loss: 1.3848 - val_accuracy: 0.5740\n",
      "Epoch 11/35\n",
      "5408/5408 - 25s - loss: 0.5400 - accuracy: 0.8347 - val_loss: 1.0076 - val_accuracy: 0.6775\n",
      "Epoch 12/35\n",
      "5408/5408 - 25s - loss: 0.4803 - accuracy: 0.8510 - val_loss: 1.0236 - val_accuracy: 0.6746\n",
      "Epoch 13/35\n",
      "5408/5408 - 25s - loss: 0.3935 - accuracy: 0.8854 - val_loss: 0.9094 - val_accuracy: 0.7071\n",
      "Epoch 14/35\n",
      "5408/5408 - 25s - loss: 0.3294 - accuracy: 0.9096 - val_loss: 1.3849 - val_accuracy: 0.6391\n",
      "Epoch 15/35\n",
      "5408/5408 - 25s - loss: 0.2673 - accuracy: 0.9320 - val_loss: 1.1725 - val_accuracy: 0.6672\n",
      "Epoch 16/35\n",
      "5408/5408 - 25s - loss: 0.2316 - accuracy: 0.9392 - val_loss: 1.2118 - val_accuracy: 0.6612\n",
      "Epoch 17/35\n",
      "5408/5408 - 25s - loss: 0.1927 - accuracy: 0.9503 - val_loss: 1.4217 - val_accuracy: 0.6213\n",
      "Epoch 18/35\n",
      "5408/5408 - 25s - loss: 0.1445 - accuracy: 0.9695 - val_loss: 1.1489 - val_accuracy: 0.6805\n",
      "Epoch 19/35\n",
      "5408/5408 - 25s - loss: 0.1261 - accuracy: 0.9730 - val_loss: 1.0717 - val_accuracy: 0.6938\n",
      "Epoch 20/35\n",
      "5408/5408 - 25s - loss: 0.0959 - accuracy: 0.9847 - val_loss: 1.0353 - val_accuracy: 0.7086\n",
      "Epoch 21/35\n",
      "5408/5408 - 25s - loss: 0.0859 - accuracy: 0.9871 - val_loss: 1.1481 - val_accuracy: 0.6953\n",
      "Epoch 22/35\n",
      "5408/5408 - 25s - loss: 0.0693 - accuracy: 0.9893 - val_loss: 1.0781 - val_accuracy: 0.7382\n",
      "Epoch 23/35\n",
      "5408/5408 - 25s - loss: 0.0592 - accuracy: 0.9911 - val_loss: 1.2136 - val_accuracy: 0.6864\n",
      "Epoch 24/35\n",
      "5408/5408 - 25s - loss: 0.0560 - accuracy: 0.9932 - val_loss: 1.8689 - val_accuracy: 0.6006\n",
      "Epoch 25/35\n",
      "5408/5408 - 25s - loss: 0.0532 - accuracy: 0.9909 - val_loss: 1.0263 - val_accuracy: 0.7367\n",
      "Epoch 26/35\n",
      "5408/5408 - 25s - loss: 0.0435 - accuracy: 0.9939 - val_loss: 1.2276 - val_accuracy: 0.7071\n",
      "Epoch 27/35\n",
      "5408/5408 - 25s - loss: 0.0366 - accuracy: 0.9950 - val_loss: 1.1794 - val_accuracy: 0.7249\n",
      "Epoch 28/35\n",
      "5408/5408 - 25s - loss: 0.0285 - accuracy: 0.9974 - val_loss: 1.4409 - val_accuracy: 0.6790\n",
      "Epoch 29/35\n",
      "5408/5408 - 25s - loss: 0.0531 - accuracy: 0.9900 - val_loss: 1.2713 - val_accuracy: 0.6893\n",
      "Epoch 30/35\n",
      "5408/5408 - 25s - loss: 0.0345 - accuracy: 0.9943 - val_loss: 1.4276 - val_accuracy: 0.6879\n",
      "Epoch 31/35\n",
      "5408/5408 - 25s - loss: 0.0470 - accuracy: 0.9906 - val_loss: 1.2333 - val_accuracy: 0.7115\n",
      "Epoch 32/35\n",
      "5408/5408 - 25s - loss: 0.0198 - accuracy: 0.9978 - val_loss: 1.0763 - val_accuracy: 0.7219\n",
      "Epoch 33/35\n",
      "5408/5408 - 25s - loss: 0.0248 - accuracy: 0.9961 - val_loss: 1.0472 - val_accuracy: 0.7234\n",
      "Epoch 34/35\n",
      "5408/5408 - 25s - loss: 0.0136 - accuracy: 0.9993 - val_loss: 0.9816 - val_accuracy: 0.7515\n",
      "Epoch 35/35\n",
      "5408/5408 - 25s - loss: 0.0121 - accuracy: 0.9993 - val_loss: 1.0521 - val_accuracy: 0.7515\n"
     ]
    }
   ],
   "source": [
    "##-- Define the optimizer\n",
    "from tensorflow.keras import optimizers, losses\n",
    "optimizer = optimizers.SGD(lr = 0.001, #--lr=0.01\n",
    "                           momentum = 0.9, #--Default: 0.9\n",
    "                           nesterov = True #--Default: False\n",
    "                           )\n",
    "# optimizer = optimizers.Adam(lr=0.01,\n",
    "#                             # beta_1=0.9, beta_2=0.999, #--Defoalt values\n",
    "#                             # amsgrad=True, #--AMSGrad\n",
    "#                             )\n",
    "##-- Compile the model\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 35\n",
    "batch_size = 64 #-- Default: 128, 64, 32\n",
    "##-- Early stopping as es\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
    "##-- Temporary save\n",
    "#--Ref. :  https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ja\n",
    "import os\n",
    "#-- ファイル名に(`str.format`を使って)エポック数を埋め込む\n",
    "checkpoint_path = \"drive/My Drive/jupyter/ProbSpace/ukiyoe/check_point/model3/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # 重みを5エポックごとに保存\n",
    "    period=5)  #--period\n",
    "##-- Run\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_data = (X_test,Y_test), #-- validation_split=0.2\n",
    "                    verbose=2, \n",
    "                    # callbacks = [cp_callback]\n",
    "                    # callbacks = [es]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1578903249921,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "iT8BX58kDM17",
    "outputId": "866d6a1f-fa38-4040-be48-710d94cd5848"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD7CAYAAACCEpQdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSvFUSaz1bmM"
   },
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3i8JbBY1ZwT"
   },
   "outputs": [],
   "source": [
    "###-- モデル全体を１つのHDF5ファイルに保存します。\n",
    "datapath_model = \"drive/My Drive/save_model/\"\n",
    "model.save(datapath_model+'model3.h5')\n",
    "\n",
    "###-- Load model file\n",
    "# model = tf.keras.models.load_model('model3.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbvZB6wdjnJD"
   },
   "source": [
    "テストデータを予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1990,
     "status": "ok",
     "timestamp": 1577941877917,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "pvU-d5tlZpFf",
    "outputId": "4f8b162e-98b5-4f20-de73-e265734df4d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "###---  提出用データの読み込み  ---###\n",
    "\n",
    "###--データの読み込み\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "X_submit = load(datapath+\"ukiyoe-test-imgs.npz\")\n",
    "\n",
    "###--型をint --> float変換する。\n",
    "X_submit = X_submit.astype(np.float32)\n",
    "###-- convert from [0:255] => [0.0:1.0]\n",
    "X_submit = np.multiply(X_submit, 1.0 / 255.0)\n",
    "\n",
    "print(X_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1577941891751,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "_SJK37dOgBfC",
    "outputId": "6058c09b-aeaf-426a-e2f2-4eade36da54b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###---  Prediction  ---###\n",
    "predicts = np.argmax(model.predict(X_submit), axis=1)\n",
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1577941895012,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "rU8_tPMIfxh8",
    "outputId": "ca988305-34ee-404f-8105-09e62b96b612"
   },
   "outputs": [],
   "source": [
    "###---  提出ファイル作成  ---###\n",
    "submit = pd.DataFrame(data={\"id\": [], \"y\": []})\n",
    "submit.id = list(range(1, predicts.shape[0]+1))\n",
    "submit.y = predicts\n",
    "submit.to_csv(\"submit.csv\", index=False)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lbeDsG67hlH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_model3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
